%!TEX root=../mythesis.tex
% Chapter 1

\chapter{Introduction} % Main chapter title
\chaptermark{Introduction}
\label{ch:chapter1} 
\section{Motivation}\label{sec:motivation}
In the context of rapid digital transformation and the accelerated advancement of Artificial Intelligence (AI), software systems have evolved from relatively static artifacts into dynamic entities. To remain effective in the face of changing requirements, technological innovations, and emerging security threats, ongoing modification and extension, collectively known as software evolution, have become an inherent and unavoidable characteristic of modern software engineering. Broadly, software evolution is primarily driven by two forces: \textbf{external adaptation}, which responds to changes in the third-party ecosystem, and \textbf{internal improvement}, which necessitates the synchronous co-evolution of implementation logic (code) and semantic interface (documentation) to satisfy evolving functional and quality requirements.

The deep integration of AI, especially Large Language Models (LLMs), into the software development lifecycle has signaled a significant paradigm shift in software evolution. Empowered by advances in artificial intelligence, intelligent development tools and autonomous agents are increasingly capable of understanding and processing large-scale codebases alongside natural language requirements, while progressively demonstrating higher-level reasoning abilities such as cross-context analysis and complicated problem decomposition. Leveraging these capabilities, AI systems can automate a wide range of labor-intensive and high-complexity tasks, such as code generation, bug fixing, documentation synchronization, and system maintenance, thereby reshaping critical stages of software evolution and enabling complex software systems to achieve continuous iteration and scalable growth at unprecedented speed. Meanwhile, this AI-driven development paradigm introduces new technical pathways for managing long-term software evolution, propelling software engineering beyond human-centered development model toward a new stage characterized by the coexistence of human–AI collaboration and autonomous intelligence.

Despite this potential, the application of LLMs in software evolution remains fundamentally constrained by their probabilistic generative nature. Although large-scale parameterization facilitates the emergence of complex reasoning capabilities, LLMs generate outputs based on learned statistical patterns rather than deterministic logic, making it a probabilistic mirage that lacks the deterministic guarantees required for reliability. At the same time, modern software is no longer an isolated entity but a node in a highly interconnected dependency network: a project is not only an internal system but also a third-party library for other projects. Allowing AI agents to arbitrarily modify code and documentation is highly risky, may inadvertently introduce new vulnerabilities or disrupt existing functionalities. In this context, even seemingly minor modifications, such as a library upgrade or internal refactoring, can propagate cascading effects that compromise system reliability, security, and maintainability at scale. 

Consequently, ensuring the reliability and robustness throughout AI-assisted software evolution can be distilled into three interrelated core challenges:

\begin{itemize}
  \item \textbf{Managing external evolutionary risks.} Reliable external adaptation is predicated on the ability of AI to foresee and mitigate the risks from third-party library upgrades. However, the scarcity of high-quality, real-world datasets that captures intricate patterns of breaking changes caused by third-party library upgrades prevents AI from evaluating and solving external dependency risks.
  \item \textbf{Maintaining internal semantic alignment.} Internal improvement requires the synchronized update of code and documentation. In practice, code and documentation are often updated asynchronously, leading to semantic drift. Since documentation serves as the outward interface for a project's dependencies, these internal inconsistencies directly amplify external usage risks. 
  \item \textbf{Achieving precise evolution execution.} Precise code localization is the prerequisite for all automated evolution tasks. However, existing LLM-based approaches still rely heavily on superficial textual cues rather than deep structural reasoning. Imprecise identification of modification scopes increases downstream overhead, raises the risk of unintended consequences, and ultimately degrades overall evolution quality.
\end{itemize}

These three challenges correspond respectively to external adaptation, internal alignment, and execution precision, together forming the central bottleneck in AI-enabled software evolution and providing the systematic research motivation and theoretical foundation for this dissertation.

\section{Contributions}\label{sec:contribution}
To address these multifaceted challenges, this dissertation advocates for a systematic and heterogeneous set of solutions. For external adaptation, we prioritize empirical grounding by constructing high-quality datasets that capture real-world breaking change patterns, thereby providing a verifiable basis for AI systems to perceive and reason about evolutionary risks. For internal improvement, our strategy is two-pronged. On one hand, we develop a multi-parameter inconsistency detection framework which combines formal engine with LLM to ensure the semantic integrity between code and documentation. On the other hand, we first formalize the \textit{Keyword Shortcut} bias in current code localization research and propose a novel neurosymbolic agent framework that offloads reasoning to a logic engine to transcend the limitations of textual context in repository-level code localization. 

Central to these solutions is the paradigm of neurosymbolic AI, which serves as the methodological foundation of this research. By synthesizing the formal rigor of symbolic logic, such as symbolic execution and Datalog, with the adaptive learning power of Large Language Models, we provide a deterministic anchor for AI-driven evolution, ensuring that complex software modifications are not only contextually aware but also logically verifiable. \fref{fig:thesis_structure} illustrates the structure of this thesis, which is organized into six chapters. The core contributions of this dissertation are summarized as follows:

\begin{itemize}
  \item \textbf{Reproducible real-world incompatibility dataset.} We construct a dataset, \toolcompsuite, including 123 reproducible, real-world client-library pairs that manifest incompatibility issues when upgrading the library. These data points originate from 88 clients and 104 libraries. We created an automated command-line interface for the dataset. With this interface, users are able to programmatically replicate an incompatibility issue from the dataset with a single command. The interface also offers separate commands for each step involved in the reproduction of incompatibility issues.
  \item \textbf{Multi-parameter code–documentation inconsistency detection.} We proposed an automated multi-parameter code-documentation inconsistency detection technique and developed an end-to-end command-line tool called \toolchecker. Existing techniques in the same area are only designed to handle single parameter inconsistencies, without considering inter-parameter constraints. We introduced a customized fuzzy constraint satisfaction framework to mitigate the uncertainties introduced by LLM outputs. We provide a theoretical derivation of the membership function based on constraint similarity. We constructed a documentation constraint dataset comprising 72 real-world constraints sourced from widely used data science libraries, and derived a mutation-based inconsistency dataset with 216 constraints. Our dataset and tool implementation are made available online: \url{https://github.com/ParsifalXu/MPChecker}. We evaluated our tool on four real-world popular data science libraries. We reported 14 inconsistency issues discovered by \toolchecker to the developers, who have confirmed 11 inconsistencies at the time of writing.
  \item \textbf{Formalization of Keyword Shortcut bias and diagnostic benchmark.} We identify and formalize the \textit{Keyword Shortcut} bias in current code localization research. To address this, we introduce \dataset, a diagnostic benchmark specifically designed for Keyword-Agnostic Logical Code Localization (KA-LCL). It contains 25 high-quality purely logical queries with precise ground-truth locations, providing a rigorous testing ground for evaluating the structural reasoning capabilities of LLMs and AI agents. We also introduce \negset, a variant of \dataset where queries are intentionally modified to ensure their ground-truth sets are empty, to evaluate the abstention capability when no valid location meets the query.
  \item \textbf{Neurosymbolic agent framework for repository-level code localization.} We proposed a novel agent-based framework for repo-level code localization that introduces program facts as an intermediate representation to capture both explicit and implicit code relationships. By synthesizing Datalog queries from natural language, \tooldataloc offloads intricate structural traversal to a high-performance deterministic reasoning engine, significantly enhancing reasoning capabilities and reducing token consumption. We implement our framework as an automated, end-to-end command-line tool. It features an iterative refinement mechanism where the LLM agent progressively generates and adjusts Datalog rules to navigate repositories. Our tool and benchmark are publicly available at: \url{https://anonymous.4open.science/r/DataLoc-EFF3}. We conduct an extensive evaluation of \tooldataloc on both \dataset and other issue-driven benchmarks. The experimental results demonstrate that \tooldataloc significantly outperforms state-of-the-art methods in KA-LCL tasks, achieving superior precision and the capacity for verifiable localization. Furthermore, \tooldataloc maintains competitive performance on standard issue-driven benchmarks, matching SOTA levels while offering higher reliability in handling negative queries through its deterministic logic.
\end{itemize}

\begin{figure}[htbp]

\begin{tikzpicture}[
    node distance = 1.5cm and 0.2em,
    chapter_node/.style = {
        align=center,
        font=\sffamily\small,
        % text width=0.28\textwidth,
        inner sep=2pt,
    },
    arrow/.style = {
        -{Stealth[scale=1.2]},
        thin
    }
]

    \node[chapter_node] (c1) {
        \textcolor{blue}{\hyperref[ch:chapter1]{\underline{\textbf{Chapter 1}}}} \\ 
        Introduction
    };

    \node[chapter_node, below=of c1] (c2) {
        \textcolor{blue}{\hyperref[ch:chapter2]{\underline{\textbf{Chapter 2}}}} \\
        Background and Literature Review
    };

    \node[chapter_node, below=1.5cm of c2] (c4) {
        \textcolor{blue}{\hyperref[ch:chapter4]{\underline{\textbf{Chapter 4}}}} \\
        \textbf{\textsc{MPChecker}:} Multi-parameter \\ 
        Code-Doc Inconsistency Detection\\ 
        \textcolor{blue}{$\bullet$ new approach}
    };

    \node[chapter_node, left= of c4] (c3) {
        \textcolor{blue}{\hyperref[ch:chapter3]{\underline{\textbf{Chapter 3}}}} \\
        \textbf{\textsc{CompSuite}:} A Dataset of Lib-\\ 
        rary Upgrade Incompatibilities\\
        \textcolor{blue}{$\bullet$ new dataset}
    };

    \node[chapter_node, right= of c4] (c5) {
        \textcolor{blue}{\hyperref[ch:chapter5]{\underline{\textbf{Chapter 5}}}} \\
        \textbf{\textsc{DataLoc}:} Neurosymbolic \\ 
        Repo-level Code Localization\\ 
        \textcolor{blue}{$\bullet$ findings \& new framework}
    };

    \node[chapter_node, below=1.5cm of c4] (c6) {
        \textcolor{blue}{\hyperref[ch:chapter6]{\underline{\textbf{Chapter 6}}}} \\
        Conclusion and Future Work
    };

    \draw[arrow] (c1.south) -- (c2.north);

    \coordinate (split) at ($(c2.south)!0.3!(c4.north)$);
    \draw (c2.south) -- (split); 

    \draw[arrow] (split) .. controls ++(0,-1.2) and ++(0,1.2) .. (c3.north);
    \draw[arrow] (split) -- (c4.north);
    \draw[arrow] (split) .. controls ++(0,-1.2) and ++(0,1.2) .. (c5.north);

    \coordinate (merge) at ($(c4.south)!0.7!(c6.north)$);

    \draw[arrow] (merge) -- (c6.north); 
    \draw (c3.south) .. controls ++(0,-1.2) and ++(0,1.2) .. (merge);
    \draw (c4.south) -- (merge);
    \draw (c5.south) .. controls ++(0,-1.2) and ++(0,1.2) .. (merge);

\end{tikzpicture}
\caption{The Structure of the Thesis}\label{fig:thesis_structure}
\end{figure}


\section{Organization}\label{sec:organization}
The rest of the thesis is organized as follows:

\begin{itemize}
  \item \hyperref[ch:chapter2]{\underline{\textbf{\cref{ch:chapter2}}}} provides essential background and key concepts necessary for understanding the thesis.
  \item \hyperref[ch:chapter3]{\underline{\textbf{\cref{ch:chapter3}}}} presents \toolcompsuite, a dataset of real-world library upgrade incompatibilities, detailing its construction, characteristics, and potential applications.
  \item \hyperref[ch:chapter4]{\underline{\textbf{\cref{ch:chapter4}}}} introduces \toolchecker, a multi-parameter code-documentation inconsistency detection tool, describing its design, implementation, and evaluation on real-world libraries.
  \item \hyperref[ch:chapter5]{\underline{\textbf{\cref{ch:chapter5}}}} formalizes the keyword shortcut bias in code localization, introduces diagnostic benchmarks, \dataset and \negset, and presents \tooldataloc, a neurosymbolic agent framework for repository-level code localization, along with its evaluation results.
  \item \hyperref[ch:chapter6]{\underline{\textbf{\cref{ch:chapter6}}}} concludes the thesis by summarizing the contributions, discussing the implications of the findings, and outlining directions for future research in AI-enabled software evolution.
\end{itemize}
