\section{Discussions}

\subsection{Threats to Validity}\label{sec:valid-mpchecker}

\textbf{Internal}
There is no established ground truth for multi-parameter code-documentation inconsistencies. To
mitigate this, we manually reviewed and verified inconsistencies detected by \toolchecker. Given the
complexity of multi-parameter constraints, two of our authors spent an additional 10 minutes per
inconsistency to verify whether it was a true positive. Moreover, many of the confirmed true positives were further validated by the original library developers, enhancing the credibility of our manual labeling. Additionally, since the GPT-4 model used in our experiments had its last knowledge update in April 2023, and our first issue submissions occurred in February 2024, the risk of data leakage is not a significant concern for our approach.


\textbf{External} Our tool may not fully generalize to all Python libraries, particularly those outside the data science domain. Although our approach is designed to be broadly applicable, we concentrated on data science libraries due to several practical considerations: (1) they are among the most widely used in the Python ecosystem, (2) they commonly employ the two major docstring formats that \toolchecker supports, and (3) they provide well-structured documentation with rich multi-parameter constraints. To enhance the representativeness of our evaluation, we selected high-quality, widely adopted libraries with comprehensive API documentation and accessible source code. A further limitation arises from the unmature Python symbolic execution tools, which may not yet robustly handle all the latest language features. Addressing these challenges will require continued engineering efforts to broaden the applicability of our tool.



\subsection{Application Prospects}

Our framework's language-agnostic design extends beyond dynamic languages like Python, such as Java, where type information facilitates more comprehensive CDI detection.

Our work represents an effective integration of LLMs and traditional software analysis, with fuzzy constraint logic (FCL) acting as the glue that enables smooth synergy between the two.  For example, LLMs have
  been recently used to infer program specifications from code~\cite{Ma2025SAG}.
  In contrast to conventional verification techniques that yield binary outcomes, either
  \texttt{True} or \texttt{False}, FCL enables probabilistic evaluation of
  invariant validity within code contexts.
  This probabilistic framework will integrate better with LLMs, which may generate close yet
  incorrect program specifications. In particular, FCL can reduce non-logical
  errors caused by confusion between similar terms.

  